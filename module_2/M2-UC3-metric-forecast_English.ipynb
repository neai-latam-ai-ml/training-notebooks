{"cells":[{"cell_type":"markdown","id":"JWnUEEbf36YP","metadata":{"id":"JWnUEEbf36YP"},"source":["# **UC3. How many subscribers will be on-line in my network next week?**"]},{"cell_type":"markdown","id":"NUHPHB0l30K7","metadata":{"id":"NUHPHB0l30K7"},"source":["For several reasons, we need to predict what the network will look like at a certain point in the future. We want to forecast traffic accurately to plan capacity provisioning in advance, forecast subscribers to plan for IP address pool capacity, and forecast user demand to plan for our K8s cluster capacity. Failure to do so could result in service unavailability, missed SLAs, and potential customer churn.\n","\n","So, how can we make reasonable predictions for a specific metric to take action now based on future forecasts? This is the main issue we aim to solve. In this case, we want to properly plan the capacity of IP address pools for our BNGs by estimating the number of subscribers expected over the coming days at different hours. If successful, this will provide a solid basis for determining the necessary size of the IP pools and provisioning them accordingly."]},{"cell_type":"markdown","id":"XAOigYNk3TfB","metadata":{"id":"XAOigYNk3TfB"},"source":["# Connection to drive and path definition (Just for Google Colab Lab)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"LT9AU6jghhch","metadata":{"id":"LT9AU6jghhch"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"tRFF14OYh2Ws","metadata":{"id":"tRFF14OYh2Ws"},"outputs":[],"source":["import sys\n","path_files ='/content/drive/MyDrive/Colab Notebooks/Files'"]},{"cell_type":"markdown","source":["# ***OR***\n","# Connection path definition (Just for AWS Jupiter Notebook)"],"metadata":{"id":"_jo-6c7hT_8q"},"id":"_jo-6c7hT_8q"},{"cell_type":"code","source":["import sys\n","path_files ='./Files'"],"metadata":{"id":"S8sebkhCUHmH"},"id":"S8sebkhCUHmH","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"IDlBZIGt3YgR","metadata":{"id":"IDlBZIGt3YgR"},"source":["# Import libraries"]},{"cell_type":"code","source":["pip install statsmodels"],"metadata":{"id":"qLJ1XSszUbpV"},"id":"qLJ1XSszUbpV","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"5bcc0754","metadata":{"id":"5bcc0754"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import mean_absolute_error,mean_absolute_percentage_error\n","import time\n","from calendar import timegm, monthrange\n","from datetime import datetime, timedelta\n","import math\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from os import listdir\n","from os.path import isfile, join\n","\n","import statsmodels.api as sm\n","from statsmodels.tsa.stattools import adfuller, kpss\n","from statsmodels.tsa.api import ExponentialSmoothing\n","from scipy.stats import iqr"]},{"cell_type":"markdown","id":"rv2IfMGS3bbw","metadata":{"id":"rv2IfMGS3bbw"},"source":["# Data Collection"]},{"cell_type":"markdown","id":"AIacyLx0FkRU","metadata":{"id":"AIacyLx0FkRU"},"source":["We will load a data set that contains number of subscribers for PE-5 for a period of 29 days, with 5 minute frequency"]},{"cell_type":"code","execution_count":null,"id":"4iu-zhHcJuib","metadata":{"id":"4iu-zhHcJuib"},"outputs":[],"source":["metric_df=pd.read_csv(join(path_files,'bng_subscribers_metric_forecast.csv'),index_col=0)"]},{"cell_type":"code","execution_count":null,"id":"819b6b01","metadata":{"id":"819b6b01"},"outputs":[],"source":["metric_df"]},{"cell_type":"markdown","id":"dwk-3L2J3iPd","metadata":{"id":"dwk-3L2J3iPd"},"source":["# Data preparation"]},{"cell_type":"code","execution_count":null,"id":"69794621","metadata":{"id":"69794621"},"outputs":[],"source":["ds_column = []\n","for i,obs in metric_df.iterrows():\n","    #new_timestamp = datetime.fromtimestamp(obs['timestamp']).strftime('%Y-%m-%d %H:%M:%S')\n","    new_timestamp = datetime.fromtimestamp(obs['timestamp'])\n","    ds_column.append(new_timestamp)\n","metric_df['ds']=ds_column\n","metric_df['y']=metric_df['bng_subscribers']\n","\n"]},{"cell_type":"code","execution_count":null,"id":"b90ac4cb","metadata":{"id":"b90ac4cb"},"outputs":[],"source":["metric_df"]},{"cell_type":"code","execution_count":null,"id":"fd50ff81","metadata":{"id":"fd50ff81"},"outputs":[],"source":["# Visualize data using seaborn\n","sns.set(rc={'figure.figsize':(12,8)})\n","sns.lineplot(x=metric_df['ds'], y=metric_df['y'])\n","plt.title('BNG Subscribers')"]},{"cell_type":"code","execution_count":null,"id":"kuh89QrXb9yP","metadata":{"id":"kuh89QrXb9yP"},"outputs":[],"source":["df = metric_df[['ds','y']].set_index('ds')\n"]},{"cell_type":"code","execution_count":null,"id":"shvv_U0sar0-","metadata":{"id":"shvv_U0sar0-"},"outputs":[],"source":["def seasonal_decompose (df):\n","    decomposition = sm.tsa.seasonal_decompose(df, model='additive',period=2016)\n","\n","    trend = decomposition.trend\n","    seasonal = decomposition.seasonal\n","    residual = decomposition.resid\n","\n","    fig = decomposition.plot()\n","    fig.set_size_inches(14, 7)\n","    plt.show()\n","\n","    return trend, seasonal, residual\n","\n","seasonal_decompose(df)"]},{"cell_type":"markdown","id":"jPGugc66GU9t","metadata":{"id":"jPGugc66GU9t"},"source":["In statsmodels, when you use *decomposition.resid*, it gives you the residual component of the time series after removing the trend and seasonality. The residual represents the part of the data that cannot be explained by the trend and seasonality, and it typically includes noise or random fluctuations."]},{"cell_type":"markdown","id":"JzdiEFF2Ma68","metadata":{"id":"JzdiEFF2Ma68"},"source":["# Naive model"]},{"cell_type":"markdown","id":"GzLmqaTQ1QI7","metadata":{"id":"GzLmqaTQ1QI7"},"source":["We want to forecast 1 day, which means 288 observations."]},{"cell_type":"markdown","id":"swORx8GbvP6X","metadata":{"id":"swORx8GbvP6X"},"source":["**Approach 1:** The \"naÃ¯ve approach\" in time series forecasting is a simple method where the forecast for the next time point is assumed to be exactly the same as the previous observed value.\n","In other words, for each new time period, the model predicts that the value will remain unchanged from the last observed value. This approach works under the assumption that there is no significant trend, seasonality, or pattern influencing future values. It is often used as a baseline model to compare the performance of more sophisticated forecasting methods.\n"]},{"cell_type":"markdown","id":"jGhXy_MJIVAf","metadata":{"id":"jGhXy_MJIVAf"},"source":["To do this, We will use the data from an entire seasonal period, which is one week (2016 observations) >>>"]},{"cell_type":"markdown","id":"l_IGgpl12dlq","metadata":{"id":"l_IGgpl12dlq"},"source":["naive prediction: y_pred = y[t-2016]"]},{"cell_type":"code","execution_count":null,"id":"JkklHlzvietr","metadata":{"id":"JkklHlzvietr"},"outputs":[],"source":["y_pred_naive = df['y'][:-2016].values.reshape(-1,1)"]},{"cell_type":"code","execution_count":null,"id":"meF1ZAW73Aw8","metadata":{"id":"meF1ZAW73Aw8"},"outputs":[],"source":["y_pred_naive.shape"]},{"cell_type":"code","execution_count":null,"id":"XSfl5Pfn2tZx","metadata":{"id":"XSfl5Pfn2tZx"},"outputs":[],"source":["df.loc[df.index[2016:],'y_pred_naive']=y_pred_naive"]},{"cell_type":"code","execution_count":null,"id":"r6EQU9h83SGM","metadata":{"id":"r6EQU9h83SGM"},"outputs":[],"source":["df"]},{"cell_type":"markdown","id":"jPWb9uT9JYb-","metadata":{"id":"jPWb9uT9JYb-"},"source":["We can estimate how well the model is performing by comparing the predicted value with the actual value of the metric at each point in time. We will use two metrics: **Mean Absolute Error** (MAE), which estimates the error based on the absolute difference. However, absolute error may not always be suitable as it does not provide a relative perspective based on the actual values. Alternatively, we have **Mean Absolute Percentage Error** (MAPE), which normalizes the error relative to the actual values, offering a better sense of the degree or proportion of deviations."]},{"cell_type":"code","execution_count":null,"id":"RFljN4mdnuxJ","metadata":{"id":"RFljN4mdnuxJ"},"outputs":[],"source":["performance_naive_MAE = mean_absolute_error(df['y'][2016:], df['y_pred_naive'][2016:])\n","print(f'The MAE for the model is {performance_naive_MAE}')\n","\n","performance_naive_MAPE = mean_absolute_percentage_error(df['y'][2016:], df['y_pred_naive'][2016:])\n","print(f'The MAPE for the model is {performance_naive_MAPE}')"]},{"cell_type":"code","execution_count":null,"id":"gWyTq7zO3tb5","metadata":{"id":"gWyTq7zO3tb5"},"outputs":[],"source":["sns.lineplot(x=df.index[7000:], y='y', data=df[7000:], color='black')\n","sns.lineplot(x=df.index[8000:8300], y='y_pred_naive', data=df[8000:8300], color='red')"]},{"cell_type":"markdown","id":"ADfAExIwMf7w","metadata":{"id":"ADfAExIwMf7w"},"source":["# Holt Winters"]},{"cell_type":"markdown","id":"ZIHVqPjjLIa2","metadata":{"id":"ZIHVqPjjLIa2"},"source":["**Approach 2:** The **Holt-Winters** technique, also known as **triple exponential smoothing**, is a forecasting method used for time series data that includes three main components:\n","\n","1. **Level (L)**: The estimate of the average or baseline value of the time series.\n","2. **Trend (T)**: The rate of change or direction in which the time series is moving (upward or downward).\n","3. **Seasonality (S)**: The repeating fluctuations occurring at regular intervals, such as daily, monthly, or yearly patterns.\n","\n","This model adjusts these three components over time, allowing for more accurate forecasts, especially in time series with seasonality and trends.\n","\n","The Holt-Winters model has two main versions:\n","- **Additive**: Used when the magnitude of seasonality is constant over time.\n","- **Multiplicative**: Used when the magnitude of seasonality changes in proportion to the trend.\n","\n","The general Holt-Winters formula involves three equations that update the level, trend, and seasonality at each time step, adjusting the forecasts according to these components."]},{"cell_type":"code","execution_count":null,"id":"vvSINwLRKc2W","metadata":{"id":"vvSINwLRKc2W"},"outputs":[],"source":["def holtwin(y_to_train, seasonal_period, predict_date):\n","\n","    holt = ExponentialSmoothing(y_to_train, seasonal_periods=seasonal_period, trend='add', seasonal='add',use_boxcox=True).fit()\n","    y_forecast = holt.forecast(predict_date).rename('Additive')\n","    return y_forecast\n"]},{"cell_type":"markdown","id":"wM_a896aM4-4","metadata":{"id":"wM_a896aM4-4"},"source":["We used the observations up to position 8000 to train the model and requested a prediction for the next 300 observations (just over one day). We also informed the model of the identified seasonality, which in this case is seven days (2016 observations)."]},{"cell_type":"markdown","source":["**Warning: Next task will last around 5 minutes**"],"metadata":{"id":"VE26HN5j5NRb"},"id":"VE26HN5j5NRb"},{"cell_type":"code","execution_count":null,"id":"7u7fgzKChU5X","metadata":{"id":"7u7fgzKChU5X"},"outputs":[],"source":["y_holtwin_pred = holtwin(df['y'][:8000],2016,300)"]},{"cell_type":"code","execution_count":null,"id":"u4vXeXLwOjH2","metadata":{"id":"u4vXeXLwOjH2"},"outputs":[],"source":["performance_holtwint_MAE = mean_absolute_error(df['y'][8000:8300], y_holtwin_pred)\n","print(f'The MAE for the model is {performance_holtwint_MAE}')\n","performance_holtwint_MAPE = mean_absolute_percentage_error(df['y'][8000:8300], y_holtwin_pred)\n","print(f'The MAPE for the model is {performance_holtwint_MAPE}')"]},{"cell_type":"code","execution_count":null,"id":"pD__0hz2Pf5j","metadata":{"id":"pD__0hz2Pf5j"},"outputs":[],"source":["sns.lineplot(x=df.index[7000:], y='y', data=df[7000:], color='black')\n","sns.lineplot(x=df.index[8000:8300], y=y_holtwin_pred, color='red')"]},{"cell_type":"markdown","id":"CJCrN2GpNCHg","metadata":{"id":"CJCrN2GpNCHg"},"source":["We can still observe a quite noisy prediction, likely due to the fact that the anomalies are causing the model to produce this variability in the forecast as well."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"17b-86MhtHHRjH5dny85MflJdlgFhDkG_","timestamp":1668336641986}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}