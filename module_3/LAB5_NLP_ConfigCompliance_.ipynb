{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435e5799",
   "metadata": {},
   "source": [
    "## **Install required packages**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3574952d-e6be-4171-8406-706962536213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting progressbar\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: progressbar\n",
      "\u001b[33m  DEPRECATION: Building 'progressbar' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'progressbar'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for progressbar (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12066 sha256=fd0581b48908b4ca181969b595f413141819ccdc90f91fbe958d139c64d83dad\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/8d/bb/b2/5353b966ac6f3c5e1000629a9a5f6aed41794487f551e32efc\n",
      "Successfully built progressbar\n",
      "Installing collected packages: progressbar\n",
      "Successfully installed progressbar-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install progressbar\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e21417c",
   "metadata": {},
   "source": [
    "## **Import requiered packages**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34375d6-eb3e-432e-af12-ae18bc901fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer,tokenizer_from_json\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import json\n",
    "import gc\n",
    "from progressbar import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26450aaf",
   "metadata": {},
   "source": [
    "## **Defined constants**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6778b1c7-fca0-4473-95cc-b07af6983cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "#configuration_template_file = 'config_template.txt'\n",
    "configuration_start_point = '!'\n",
    "test_samples = 10\n",
    "context_before = 50\n",
    "context_after = 50\n",
    "max_dictionary_size = 50000\n",
    "top_n_probabilities = 10\n",
    "probability_threshold = 3\n",
    "word_variability_threshold = 10\n",
    "latent_len = 512\n",
    "training_size = 100000\n",
    "testing_size = 2000\n",
    "total_subset = training_size+testing_size\n",
    "batch_size = 1024\n",
    "nb_epoch = 10\n",
    "training_steps_per_epoch = int(np.ceil(training_size/batch_size))\n",
    "validation_steps_per_epoch = int(np.ceil(testing_size/batch_size))\n",
    "test_file = 'config_test.cfg'\n",
    "tokenizer_file = 'tokenizer-pe.json'\n",
    "model_weights_file = 'weights_config_anomaly_PE_blstm.weights.h5'\n",
    "path_config_files = './configs'\n",
    "path_files = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa21cc18",
   "metadata": {},
   "source": [
    "## **Define functions**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e33e37ac-7641-4c95-bd8b-3d87480b9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def config_train_test_split(target_configs, test_samples):\n",
    "  test_files_indexes = random.sample(range(len(target_configs)),test_samples)\n",
    "  train_configs = []\n",
    "  test_configs = []\n",
    "  for i in range(len(target_configs)):\n",
    "    if i in test_files_indexes:\n",
    "      test_configs.append(target_configs[i])\n",
    "    else:\n",
    "      train_configs.append(target_configs[i])\n",
    "  return train_configs,test_configs\n",
    "\n",
    "def find_config_start(config_lines, start_sequence):\n",
    "  i=0\n",
    "  config_found = np.False_\n",
    "  while not config_found:\n",
    "    if start_sequence in config_lines[i]:\n",
    "      config_found = True\n",
    "      config_index = i+1\n",
    "    else:\n",
    "      i+=1\n",
    "  return config_index\n",
    "\n",
    "def get_lines(config_file):\n",
    "  file_handle = open(config_file, 'r')\n",
    "  config_lines = file_handle.readlines()\n",
    "  return config_lines\n",
    "\n",
    "def get_config_lines(config_file):\n",
    "  file_handle = open(config_file, 'r')\n",
    "  config_lines = file_handle.readlines()\n",
    "  config_index = find_config_start(config_lines,configuration_start_point)\n",
    "  return config_lines[config_index:]\n",
    "\n",
    "def build_corpus(train_configs,path):\n",
    "  for config_file in train_configs:\n",
    "    corpus = []\n",
    "    print('Config:',config_file)\n",
    "    config_lines = get_config_lines(join(path,config_file))\n",
    "    for i in range(len(config_lines)):\n",
    "      corpus += config_lines[i].lower().split()\n",
    "    yield corpus\n",
    "\n",
    "def build_tokenizer(train_configs, path):\n",
    "  tokenizer = Tokenizer(filters='',oov_token='OOV',num_words=max_dictionary_size)\n",
    "  tokenizer.fit_on_texts(build_corpus(train_configs,path))\n",
    "  total_words = len(tokenizer.word_index) + 1\n",
    "  print(total_words)\n",
    "  return tokenizer\n",
    "\n",
    "def build_training_data(train_config, tokenizer):\n",
    "  input_sequences = []\n",
    "  input_labels = []\n",
    "  current_index = 0\n",
    "  corpus = []\n",
    "  config_lines = get_config_lines(train_config)\n",
    "  for i in range(len(config_lines)):\n",
    "      corpus += config_lines[i].lower().split()\n",
    "  while (current_index + context_before + context_after+1) < len(corpus):\n",
    "    current_sequence = corpus[current_index:(current_index+context_before)]+corpus[(current_index+context_before+1):(current_index+context_before+context_after+1)]\n",
    "    current_label = corpus[current_index+context_before]\n",
    "    token_list = tokenizer.texts_to_sequences([current_sequence])[0]\n",
    "    token_label = tokenizer.texts_to_sequences([current_label])[0]\n",
    "    input_sequences.append(token_list)\n",
    "    input_labels.append(token_label)\n",
    "    current_index +=1\n",
    "  xs, labels = np.array(input_sequences),np.array(input_labels)\n",
    "  ys = tf.keras.utils.to_categorical(labels, num_classes=(dictionary_size))\n",
    "  return xs,ys\n",
    "\n",
    "def build_training_data_batch(corpus, tokenizer, start_index, batch_size):\n",
    "  input_sequences = []\n",
    "  input_labels = []\n",
    "  current_index = start_index\n",
    "  config_finished=False\n",
    "  for i in range(batch_size):\n",
    "    if (current_index + context_before + context_after) < len(corpus):\n",
    "      current_sequence = corpus[current_index:(current_index+context_before)]+corpus[(current_index+context_before+1):(current_index+context_before+context_after+1)]\n",
    "      current_label = corpus[current_index+context_before]\n",
    "      token_list = tokenizer.texts_to_sequences([current_sequence])[0]\n",
    "      token_label = tokenizer.texts_to_sequences([current_label])[0]\n",
    "      input_sequences.append(token_list)\n",
    "      input_labels.append(token_label)\n",
    "      current_index +=1\n",
    "    else:\n",
    "      config_finished = True\n",
    "  xs, labels = np.array(input_sequences),np.array(input_labels)\n",
    "  ys = tf.keras.utils.to_categorical(labels, num_classes=(dictionary_size))\n",
    "  return xs,ys,config_finished\n",
    "\n",
    "def batch_generator(train_configs,path, batch_size, steps):\n",
    "  xs = []\n",
    "  ys = []\n",
    "  i=0\n",
    "  idx_total=1\n",
    "  while True:\n",
    "    config=train_configs[i]\n",
    "    corpus = []\n",
    "    config_lines=get_config_lines(join(path,config))\n",
    "    for j in range(len(config_lines)):\n",
    "      corpus += config_lines[j].lower().split()\n",
    "\n",
    "    idx=1\n",
    "    del xs\n",
    "    del ys\n",
    "    gc.collect()\n",
    "    done_yet = False\n",
    "    while not done_yet:\n",
    "      start_index = (idx-1)*batch_size\n",
    "      xs,ys,done_yet = build_training_data_batch(corpus,tokenizer,start_index,batch_size)\n",
    "      stop_index = start_index + batch_size\n",
    "      X_batch = xs\n",
    "      y_batch = ys\n",
    "      yield (X_batch,y_batch)\n",
    "      if not done_yet:\n",
    "        if idx_total < steps:\n",
    "            idx +=1\n",
    "            idx_total +=1\n",
    "        else:\n",
    "            idx_total=1\n",
    "            done_yet=True\n",
    "      else:\n",
    "        if idx < steps:\n",
    "            idx +=1\n",
    "            if i<(len(train_configs)-1):\n",
    "              i+=1\n",
    "            else:\n",
    "              i=0\n",
    "        else:\n",
    "            idx_total=1\n",
    "            i=0\n",
    "\n",
    "def predict_config_accuracy(config_file, model, tokenizer):\n",
    "  xs,ys = build_training_data(config_file, tokenizer)\n",
    "  score, acc = model.evaluate(xs[0:2000], ys[0:2000])\n",
    "  return score, acc\n",
    "\n",
    "def predict_config(config_file, model, tokenizer):\n",
    "  xs,ys = build_training_data(config_file, tokenizer)\n",
    "  y_pred = model(xs[0:1000])\n",
    "  return y_pred\n",
    "\n",
    "def convert_to_text(y_pred, tokenizer):\n",
    "  predicted_words_index = [int(np.argmax(y_pred[i,:])) for i in range(y_pred.shape[0])]\n",
    "  predicted_words = tokenizer.sequences_to_texts([predicted_words_index])[0]\n",
    "  return predicted_words\n",
    "\n",
    "def compute_config_anomaly_vector(config_file, model, tokenizer):\n",
    "  xs,ys = build_training_data(config_file, tokenizer)\n",
    "  #predicted_prob = model.predict_proba(xs, verbose=0)\n",
    "  y_pred = model(xs).numpy()\n",
    "  real_words_index = [int(np.argmax(ys[i,:])) for i in range(ys.shape[0])]\n",
    "  y_probability = []\n",
    "  y_recommended = []\n",
    "  y_prob_conf = []\n",
    "  for i in range(1,y_pred.shape[0]):\n",
    "    temp = np.partition(-y_pred[i,:], top_n_probabilities)\n",
    "    y_pred_average=np.mean(-temp[:top_n_probabilities])\n",
    "    y_pred_prob = y_pred[i,real_words_index[i]]\n",
    "    y_recom = np.argmax(y_pred[i,:])\n",
    "    word_variability = total_nexts[real_words_index[i-1]]\n",
    "    y_prob_conf = y_pred_prob/y_pred_average\n",
    "    if word_variability > word_variability_threshold:\n",
    "      probability = top_n_probabilities\n",
    "    else:\n",
    "      probability = y_pred_prob/y_pred_average\n",
    "    y_probability.append(probability)\n",
    "    y_recommended.append(y_recom)\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.hist(y_prob_conf, bins=30)\n",
    "  return y_probability,y_recommended\n",
    "\n",
    "def display_config_anomalies(config_file,model,tokenizer):\n",
    "  y_probability,y_recommended = compute_config_anomaly_vector(config_file,model,tokenizer)\n",
    "  config_lines = get_config_lines(config_file)\n",
    "  corpus = []\n",
    "  for i in range(len(config_lines)):\n",
    "      corpus += config_lines[i].lower().split()\n",
    "  y_words = corpus[context_before+1:-(context_after+1)]\n",
    "  probability_mask = np.array(y_probability) > probability_threshold\n",
    "  print('Number of anomalies detected:',(len(y_words)-np.sum(probability_mask)))\n",
    "  colored_config = ''\n",
    "  word_index = 0\n",
    "  for w in range(len(config_lines)):\n",
    "    tokenized_line = config_lines[w].split()\n",
    "    for item in tokenized_line:\n",
    "      if word_index>=(context_before+1) and word_index<(len(corpus)-(context_after+1)):\n",
    "        if probability_mask[word_index-(context_before+1)]:\n",
    "          colored_config += '\\033[92m '+item\n",
    "        else:\n",
    "          colored_config += '\\033[91m '+item + '(expected: '+tokenizer.sequences_to_texts([[y_recommended[word_index-(context_before+1)]]])[0]+')'\n",
    "      else:\n",
    "          colored_config += '\\033[94m '+item\n",
    "      word_index+=1\n",
    "    colored_config += '\\n'\n",
    "\n",
    "  print(colored_config)\n",
    "  return y_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097763f3",
   "metadata": {},
   "source": [
    "## **Load config files, divide the set (train/test), generate tokens**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3db1759-8eec-4ac9-8f21-d2b64810bafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: config_PE-4.cfg\n",
      "Config: config_PE-8.cfg\n",
      "Config: config_PE-71.cfg\n",
      "Config: config_PE-74.cfg\n",
      "Config: config_PE-91.cfg\n",
      "Config: config_PE-5.cfg\n",
      "Config: config_PE-24.cfg\n",
      "Config: config_PE-79.cfg\n",
      "Config: config_PE-54.cfg\n",
      "Config: config_PE-59.cfg\n",
      "Config: config_PE-86.cfg\n",
      "Config: config_PE-13.cfg\n",
      "Config: config_PE-10.cfg\n",
      "Config: config_PE-64.cfg\n",
      "Config: config_PE-9.cfg\n",
      "Config: config_PE-70.cfg\n",
      "Config: config_PE-67.cfg\n",
      "Config: config_PE-47.cfg\n",
      "Config: config_PE-29.cfg\n",
      "Config: config_PE-75.cfg\n",
      "Config: config_PE-68.cfg\n",
      "Config: config_PE-42.cfg\n",
      "Config: config_PE-32.cfg\n",
      "Config: config_PE-97.cfg\n",
      "Config: config_PE-3.cfg\n",
      "Config: config_PE-15.cfg\n",
      "Config: config_PE-62.cfg\n",
      "Config: config_PE-39.cfg\n",
      "Config: config_PE-82.cfg\n",
      "Config: config_PE-65.cfg\n",
      "Config: config_PE-28.cfg\n",
      "Config: config_PE-61.cfg\n",
      "Config: config_PE-22.cfg\n",
      "Config: config_PE-98.cfg\n",
      "Config: config_PE-12.cfg\n",
      "Config: config_PE-30.cfg\n",
      "Config: config_PE-14.cfg\n",
      "Config: config_PE-25.cfg\n",
      "Config: config_PE-99.cfg\n",
      "Config: config_PE-81.cfg\n",
      "Config: config_PE-49.cfg\n",
      "Config: config_PE-40.cfg\n",
      "Config: config_PE-56.cfg\n",
      "Config: config_PE-92.cfg\n",
      "Config: config_PE-17.cfg\n",
      "Config: config_PE-45.cfg\n",
      "Config: config_PE-77.cfg\n",
      "Config: config_PE-66.cfg\n",
      "Config: config_PE-37.cfg\n",
      "Config: config_PE-20.cfg\n",
      "Config: config_PE-43.cfg\n",
      "Config: config_PE-93.cfg\n",
      "Config: config_PE-19.cfg\n",
      "Config: config_PE-73.cfg\n",
      "Config: config_PE-87.cfg\n",
      "Config: config_PE-69.cfg\n",
      "Config: config_PE-1.cfg\n",
      "Config: config_PE-55.cfg\n",
      "Config: config_PE-18.cfg\n",
      "Config: config_PE-76.cfg\n",
      "Config: config_PE-50.cfg\n",
      "Config: config_PE-51.cfg\n",
      "Config: config_PE-80.cfg\n",
      "Config: config_PE-57.cfg\n",
      "Config: config_PE-100.cfg\n",
      "Config: config_PE-36.cfg\n",
      "Config: config_PE-21.cfg\n",
      "Config: config_PE-44.cfg\n",
      "Config: config_PE-89.cfg\n",
      "Config: config_PE-2.cfg\n",
      "Config: config_PE-7.cfg\n",
      "Config: config_PE-52.cfg\n",
      "Config: config_PE-11.cfg\n",
      "Config: config_PE-16.cfg\n",
      "Config: config_PE-48.cfg\n",
      "Config: config_PE-72.cfg\n",
      "Config: config_PE-53.cfg\n",
      "Config: config_PE-41.cfg\n",
      "Config: config_PE-6.cfg\n",
      "Config: config_PE-94.cfg\n",
      "Config: config_PE-38.cfg\n",
      "Config: config_PE-60.cfg\n",
      "Config: config_PE-83.cfg\n",
      "Config: config_PE-33.cfg\n",
      "Config: config_PE-95.cfg\n",
      "Config: config_PE-96.cfg\n",
      "Config: config_PE-84.cfg\n",
      "Config: config_PE-78.cfg\n",
      "Config: config_PE-23.cfg\n",
      "Config: config_PE-35.cfg\n",
      "1773\n"
     ]
    }
   ],
   "source": [
    "config_files = [f for f in listdir(path_config_files) if (isfile(join(path_config_files, f)))]\n",
    "\n",
    "train_configs, test_configs = config_train_test_split(config_files, test_samples)\n",
    "\n",
    "#print('Training configs:',train_configs)\n",
    "#print('Testing configs:',test_configs)\n",
    "\n",
    "tokenizer = build_tokenizer(train_configs, path_config_files)\n",
    "\n",
    "tokenizer_json = tokenizer.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8538359",
   "metadata": {},
   "source": [
    "## **Save tokens to file**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402cb25a-2d05-42fa-985d-ef65ffef8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(\"./\", tokenizer_file), 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "\n",
    "with open(join(\"./\",tokenizer_file)) as f:\n",
    "    data = json.load(f)\n",
    "    tokenizer = tokenizer_from_json(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feaa856",
   "metadata": {},
   "source": [
    "## **Review discovered vocabulary**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0772f577-5798-47bf-bb2b-84011bd61952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 1773\n"
     ]
    }
   ],
   "source": [
    "total_words = len(tokenizer.word_index)+1\n",
    "dictionary_size= min(total_words,max_dictionary_size)\n",
    "print('Dictionary size:',dictionary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd67be",
   "metadata": {},
   "source": [
    "## **Get word contexts**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946517bc-0fbd-4cbc-8bb7-74968c71ea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "total_next_words = []\n",
    "for w in range(total_words):\n",
    "  total_next_words.append([])\n",
    "total_nexts = [0 for i in range(total_words)]\n",
    "pbar = ProgressBar()\n",
    "\n",
    "for config in pbar(train_configs):\n",
    "  corpus = []\n",
    "  config_lines = get_config_lines(join(path_config_files,config))\n",
    "  for i in range(len(config_lines)):\n",
    "    corpus += config_lines[i].lower().split()\n",
    "  for i in range(len(corpus)-1):\n",
    "    current_token = tokenizer.texts_to_sequences([corpus[i]])[0][0]\n",
    "    next_token = tokenizer.texts_to_sequences([corpus[i+1]])[0][0]\n",
    "    current_token_nexts = total_next_words[current_token]\n",
    "    if next_token not in current_token_nexts:\n",
    "      total_next_words[current_token].append(next_token)\n",
    "      total_nexts[current_token]+=1\n",
    "        \n",
    "my_training_batch_generator = batch_generator(train_configs, path_config_files, batch_size, training_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd708f2a",
   "metadata": {},
   "source": [
    "## **Define the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256cdc6e-7bea-4dfb-9c0f-bdda3a558a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1748387941.508378   40350 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1376 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">177,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1773</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">455,661</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1773</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │       \u001b[38;5;34m177,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m234,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1773\u001b[0m)           │       \u001b[38;5;34m455,661\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1773\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">867,457</span> (3.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m867,457\u001b[0m (3.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">867,457</span> (3.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m867,457\u001b[0m (3.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mymodel = tf.keras.Sequential()\n",
    "mymodel.add(Embedding(dictionary_size, 100, input_length=(context_before+context_after)))\n",
    "mymodel.add(Bidirectional(LSTM(128,recurrent_dropout=0.1)))\n",
    "mymodel.add(Dense(dictionary_size,activation='softmax'))\n",
    "mymodel.add(layers.Dropout(0.1))\n",
    "input_shape_for_build = (None, context_before + context_after)\n",
    "mymodel.build(input_shape=input_shape_for_build)\n",
    "mymodel.summary()\n",
    "adam = Adam(learning_rate=0.01)\n",
    "mymodel.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2d69f",
   "metadata": {},
   "source": [
    "## **Print model architecture (layers)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54eaa1-b333-4120-b4c8-f3befa49febe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/ubuntu/venv/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in /home/ubuntu/venv/lib/python3.11/site-packages (from pydot) (3.2.3)\n",
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.keras.utils.plot_model(mymodel,show_shapes=True,show_dtype=True,show_layer_names=True,show_layer_activations=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c4f15",
   "metadata": {},
   "source": [
    "## **Save/Load model weights**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "264226bc-f00b-4ea8-97ad-1fbfa1abc338",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.save_weights(join(path_files, model_weights_file))\n",
    "mymodel.load_weights(join(path_files, model_weights_file))\n",
    "\n",
    "filepath=join(path_files, model_weights_file)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db93c02b",
   "metadata": {},
   "source": [
    "## **Start training**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b95e8eff-22a5-4e26-acfb-432b73d0e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.3375 - loss: 4.7278\n",
      "Epoch 1: loss improved from inf to 3.21403, saving model to ./weights_config_anomaly_PE_blstm.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 378ms/step - accuracy: 0.3402 - loss: 4.7125\n",
      "Epoch 2/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8638 - loss: 1.8898\n",
      "Epoch 2: loss improved from 3.21403 to 1.87075, saving model to ./weights_config_anomaly_PE_blstm.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 379ms/step - accuracy: 0.8638 - loss: 1.8896\n",
      "Epoch 3/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8650 - loss: 1.8490\n",
      "Epoch 3: loss improved from 1.87075 to 1.83583, saving model to ./weights_config_anomaly_PE_blstm.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 381ms/step - accuracy: 0.8650 - loss: 1.8489\n",
      "Epoch 4/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8672 - loss: 1.8130\n",
      "Epoch 4: loss improved from 1.83583 to 1.80947, saving model to ./weights_config_anomaly_PE_blstm.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 379ms/step - accuracy: 0.8672 - loss: 1.8129\n",
      "Epoch 5/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8668 - loss: 1.8086\n",
      "Epoch 5: loss did not improve from 1.80947\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 378ms/step - accuracy: 0.8668 - loss: 1.8087\n",
      "Epoch 6/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8674 - loss: 1.7878\n",
      "Epoch 6: loss improved from 1.80947 to 1.78365, saving model to ./weights_config_anomaly_PE_blstm.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 380ms/step - accuracy: 0.8674 - loss: 1.7878\n",
      "Epoch 7/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8622 - loss: 1.8800\n",
      "Epoch 7: loss did not improve from 1.78365\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 378ms/step - accuracy: 0.8623 - loss: 1.8794\n",
      "Epoch 8/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8668 - loss: 1.7880\n",
      "Epoch 8: loss improved from 1.78365 to 1.78287, saving model to ./weights_config_anomaly_PE_blstm.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 379ms/step - accuracy: 0.8668 - loss: 1.7880\n",
      "Epoch 9/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8679 - loss: 1.7985\n",
      "Epoch 9: loss improved from 1.78287 to 1.77628, saving model to ./weights_config_anomaly_PE_blstm.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 374ms/step - accuracy: 0.8679 - loss: 1.7983\n",
      "Epoch 10/10\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8719 - loss: 1.7443\n",
      "Epoch 10: loss improved from 1.77628 to 1.76318, saving model to ./weights_config_anomaly_PE_blstm.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 379ms/step - accuracy: 0.8719 - loss: 1.7445\n"
     ]
    }
   ],
   "source": [
    "history = mymodel.fit(my_training_batch_generator,\n",
    "                      epochs=nb_epoch,\n",
    "                      steps_per_epoch=training_steps_per_epoch,\n",
    "                      verbose=1,\n",
    "                      callbacks=callbacks_list\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653d830",
   "metadata": {},
   "source": [
    "## **Use model to review config-compliance deviation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddcbdcd-5aab-446f-bf1f-0e6e9f7202f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9813 - loss: 0.2820\n",
      "Number of anomalies detected: 4\n",
      "\u001b[94m !Image:\u001b[94m Copyright\u001b[94m (C)\u001b[94m 2020\u001b[94m your\u001b[94m favorite\u001b[94m vendor.\u001b[94m All\u001b[94m rights\u001b[94m reserved\n",
      "\u001b[94m !Image:\u001b[94m Software\u001b[94m Product:\u001b[94m IOS-XR,\u001b[94m Version:\u001b[94m 7.6R3\n",
      "\u001b[94m !Image:\u001b[94m Hardware\u001b[94m Model:\u001b[94m ASR\n",
      "\u001b[94m !Image:\u001b[94m Software\u001b[94m Feature\u001b[94m Code:\u001b[94m SP\n",
      "\u001b[94m !Image:\u001b[94m System\u001b[94m Configuration\u001b[94m Code:\u001b[94m S3\n",
      "\u001b[94m !Image:\u001b[94m Package\u001b[94m Configuration\u001b[94m Code:\u001b[94m P4\n",
      "\u001b[94m !Image:\u001b[94m Software\u001b[94m Baseline\u001b[94m Version:\u001b[94m 2.3.5\n",
      "\u001b[94m !Image:\u001b[94m Installation\u001b[94m Information:\n",
      "\u001b[94m !Image:\u001b[94m Image\u001b[94m Filename:\u001b[94m IOS-XR-7-6-R-3\n",
      "\u001b[94m !Image:\u001b[94m ONIE\u001b[94m SysInfo:\u001b[94m x86_64-accton_asr7736_64x-r0\n",
      "\u001b[92m !\n",
      "\u001b[92m !\n",
      "\u001b[92m !\n",
      "\u001b[92m !\n",
      "\u001b[92m !\n",
      "\u001b[92m !\n",
      "\u001b[92m !\u001b[92m Software\u001b[92m version:\u001b[92m IOS-XR\u001b[91m 6.5R4(expected: 7.6r3)\n",
      "\u001b[92m !\n",
      "\u001b[92m !\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m cml\u001b[92m 5\n",
      "\u001b[92m !\n",
      "\u001b[92m service\u001b[92m password-encryption\n",
      "\u001b[92m !\n",
      "\u001b[92m enable\u001b[92m confirmation-dialog\n",
      "\u001b[92m !\n",
      "\u001b[92m no\u001b[92m logging\u001b[92m console\n",
      "\u001b[92m no\u001b[92m logging\u001b[92m monitor\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m nsm\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m rip\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m ripng\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m ospf\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m ospf6\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m isis\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m hostp\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m mrib\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m pim\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m auth\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m mstp\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m onm\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m hsl\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m oam\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m vlog\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m trill\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m vrrp\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m ndd\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m rib\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m bgp\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m l2mrib\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m lag\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m sflow\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m pserv\u001b[92m 5\n",
      "\u001b[92m logging\u001b[92m level\u001b[92m cmm\u001b[92m 5\n",
      "\u001b[92m banner\u001b[92m motd\u001b[92m ***\u001b[92m Configuration\u001b[92m should\u001b[92m not\u001b[92m be\u001b[92m changed\u001b[92m manually\u001b[92m ***\n",
      "\u001b[92m !\n",
      "\u001b[92m ip\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m !\n",
      "\u001b[92m bfd\u001b[92m interval\u001b[92m 3\u001b[92m minrx\u001b[92m 3\u001b[92m multiplier\u001b[92m 3\n",
      "\u001b[92m !\n",
      "\u001b[92m load-balance\u001b[92m prof1\n",
      "\u001b[92m load-balance\u001b[92m prof1\u001b[92m macro-flow\n",
      "\u001b[92m load-balance\u001b[92m prof1\u001b[92m ipv4\u001b[92m dest-ipv4\u001b[92m src-ipv4\u001b[92m destl4-port\u001b[92m srcl4-port\u001b[92m protocol-id\n",
      "\u001b[92m load-balance\u001b[92m prof1\u001b[92m ipv6\u001b[92m dest-ipv6\u001b[92m src-ipv6\u001b[92m destl4-port\u001b[92m srcl4-port\u001b[92m next-hdr\n",
      "\u001b[92m load-balance\u001b[92m prof1\u001b[92m vxlan\u001b[92m inner-l3\u001b[92m dest-ip\u001b[92m src-ip\u001b[92m destl4-port\u001b[92m srcl4-port\u001b[92m protocol-id\n",
      "\u001b[92m forwarding\u001b[92m profile\u001b[92m l2-profile-three\n",
      "\u001b[92m !\n",
      "\u001b[92m qos\u001b[92m enable\n",
      "\u001b[92m qos\u001b[92m statistics\n",
      "\u001b[92m !\n",
      "\u001b[92m hostname\u001b[92m PE-100\n",
      "\u001b[92m no\u001b[92m ip\u001b[92m domain-lookup\n",
      "\u001b[92m ip\u001b[92m domain-lookup\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m ip\u001b[92m domain-name\u001b[92m vrf\u001b[92m management\u001b[92m mlfornetworkengineers.ai\n",
      "\u001b[92m ip\u001b[92m name-server\u001b[92m vrf\u001b[92m management\u001b[92m 8.8.8.8\n",
      "\u001b[92m ip\u001b[92m name-server\u001b[92m vrf\u001b[92m management\u001b[92m 8.8.8.9\n",
      "\u001b[92m errdisable\u001b[92m cause\u001b[92m link-flap\n",
      "\u001b[92m no\u001b[92m errdisable\u001b[92m cause\u001b[92m stp-bpdu-guard\n",
      "\u001b[92m errdisable\u001b[92m link-flap-setting\u001b[92m max-flaps\u001b[92m 5\u001b[92m time\u001b[92m 60\n",
      "\u001b[92m no\u001b[92m feature\u001b[92m telnet\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m feature\u001b[92m ssh\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m feature\u001b[92m tacacs+\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m tacacs-server\u001b[92m login\u001b[92m host\u001b[92m 10.15.1.10\u001b[92m vrf\u001b[92m management\u001b[92m seq-num\u001b[92m 1\u001b[92m key\u001b[92m 7\u001b[92m 0x960c890aa72610d6aca0\u001b[92m port\u001b[92m 1623\n",
      "\u001b[92m tacacs-server\u001b[92m login\u001b[92m host\u001b[91m 10.15.2.11(expected: 10.15.1.11)\u001b[92m vrf\u001b[92m management\u001b[92m seq-num\u001b[92m 2\u001b[92m key\u001b[92m 7\u001b[92m 0x960c890a272610d6aca0\u001b[92m port\u001b[92m 1623\n",
      "\u001b[92m aaa\u001b[92m local\u001b[92m authentication\u001b[92m unlock-timeout\u001b[92m 1\n",
      "\u001b[92m aaa\u001b[92m authentication\u001b[92m login\u001b[92m default\u001b[92m vrf\u001b[92m management\u001b[92m group\u001b[92m tacacs+\u001b[92m local\n",
      "\u001b[92m snmp-server\u001b[92m enable\u001b[92m snmp\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m snmp-server\u001b[92m view\u001b[92m all\u001b[92m .1\u001b[92m included\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m snmp-server\u001b[92m community\u001b[92m test\u001b[92m group\u001b[92m network-operator\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m snmp-server\u001b[92m host\u001b[92m 10.15.1.12\u001b[92m traps\u001b[92m version\u001b[92m 2c\u001b[92m test\u001b[92m udp-port\u001b[92m 162\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m snmp-server\u001b[92m host\u001b[92m 10.15.1.13\u001b[92m traps\u001b[92m version\u001b[92m 2c\u001b[92m test\u001b[92m udp-port\u001b[92m 162\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m feature\u001b[92m ntp\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m ntp\u001b[92m enable\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m ntp\u001b[92m server\u001b[92m 10.15.1.14\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m username\u001b[92m admin\u001b[92m role\u001b[92m network-admin\u001b[92m password\u001b[92m encrypted\u001b[92m $1hde642ysfh5eyw3\n",
      "\u001b[92m no\u001b[92m username\u001b[92m ios\n",
      "\u001b[92m feature\u001b[92m rsyslog\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m logging\u001b[92m server\u001b[92m 10.15.1.15\u001b[92m 5\u001b[92m facility\u001b[92m local0\u001b[92m vrf\u001b[92m management\n",
      "\u001b[92m !\n",
      "\n",
      "\u001b[92m interface\u001b[92m et-1-1-1\n",
      "\u001b[92m description\u001b[92m core:400G:PE-100-et-1-1-1\u001b[92m C-1\u001b[92m et-1-1-100\n",
      "\u001b[92m load-interval\u001b[92m 30\n",
      "\u001b[92m ip\u001b[92m address\u001b[92m 11.1.100.2/30\n",
      "\u001b[92m mtu\u001b[92m 9000\n",
      "\u001b[92m port-channel\u001b[92m load-balance\u001b[92m prof1\n",
      "\u001b[92m port-channel\u001b[92m min-links\u001b[92m 2\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m network\u001b[92m point-to-point\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m cost\u001b[92m 10000\n",
      "\u001b[92m !\n",
      "\u001b[92m interface\u001b[92m et-1-1-2\n",
      "\u001b[92m description\u001b[92m core:400G:PE-100-et-1-1-2\u001b[92m C-2\u001b[92m et-1-1-100\n",
      "\u001b[92m load-interval\u001b[92m 30\n",
      "\u001b[92m ip\u001b[92m address\u001b[92m 11.2.100.2/30\n",
      "\u001b[92m mtu\u001b[91m 9001(expected: 9000)\n",
      "\u001b[92m port-channel\u001b[92m load-balance\u001b[92m prof1\n",
      "\u001b[92m port-channel\u001b[92m min-links\u001b[92m 2\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m network\u001b[92m point-to-point\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m cost\u001b[92m 10000\n",
      "\u001b[92m !\n",
      "\u001b[92m interface\u001b[92m et-1-1-3\n",
      "\u001b[92m description\u001b[92m core:400G:PE-100-et-1-1-3\u001b[92m C-3\u001b[92m et-1-1-100\n",
      "\u001b[92m load-interval\u001b[92m 30\n",
      "\u001b[92m ip\u001b[92m address\u001b[92m 11.3.100.2/30\n",
      "\u001b[92m mtu\u001b[92m 9000\n",
      "\u001b[92m port-channel\u001b[92m load-balance\u001b[92m prof1\n",
      "\u001b[92m port-channel\u001b[92m min-links\u001b[92m 2\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m network\u001b[92m point-to-point\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m cost\u001b[92m 10000\n",
      "\u001b[92m !\n",
      "\u001b[92m interface\u001b[92m et-1-1-4\n",
      "\u001b[92m description\u001b[92m core:400G:PE-100-et-1-1-4\u001b[92m C-4\u001b[92m et-1-1-100\n",
      "\u001b[92m load-interval\u001b[92m 30\n",
      "\u001b[92m ip\u001b[92m address\u001b[92m 11.4.100.2/30\n",
      "\u001b[92m mtu\u001b[92m 9000\n",
      "\u001b[92m port-channel\u001b[92m load-balance\u001b[92m prof1\n",
      "\u001b[92m port-channel\u001b[92m min-links\u001b[92m 2\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m network\u001b[92m point-to-point\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m cost\u001b[92m 10000\n",
      "\u001b[92m !\n",
      "\n",
      "\u001b[92m interface\u001b[92m et-1-2-1\n",
      "\u001b[92m description\u001b[92m edge:10G:PE-100-et-1-2-1\u001b[92m E-100-1\u001b[92m et-1-1-1\n",
      "\u001b[92m load-interval\u001b[92m 30\n",
      "\u001b[92m ip\u001b[92m address\u001b[92m 12.100.1.1/30\n",
      "\u001b[92m mtu\u001b[92m 1500\n",
      "\u001b[92m port-channel\u001b[92m load-balance\u001b[92m prof1\n",
      "\u001b[92m port-channel\u001b[92m min-links\u001b[92m 2\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m network\u001b[92m point-to-point\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m cost\u001b[92m 1000\n",
      "\u001b[92m !\n",
      "\u001b[92m interface\u001b[92m et-1-2-2\n",
      "\u001b[92m description\u001b[92m edge:10G:PE-100-et-1-2-2\u001b[92m E-100-2\u001b[92m et-1-1-1\n",
      "\u001b[92m load-interval\u001b[92m 30\n",
      "\u001b[92m ip\u001b[92m address\u001b[92m 12.100.2.1/30\n",
      "\u001b[92m mtu\u001b[91m 9000(expected: 1500)\n",
      "\u001b[92m port-channel\u001b[92m load-balance\u001b[92m prof1\n",
      "\u001b[92m port-channel\u001b[92m min-links\u001b[92m 2\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m network\u001b[92m point-to-point\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m cost\u001b[92m 1000\n",
      "\u001b[92m !\n",
      "\n",
      "\n",
      "\u001b[92m interface\u001b[92m eth0\n",
      "\u001b[92m ip\u001b[92m vrf\u001b[92m forwarding\u001b[92m management\n",
      "\u001b[92m ip\u001b[92m address\u001b[92m 10.2.2.100\n",
      "\u001b[92m !\n",
      "\u001b[92m interface\u001b[92m lo\n",
      "\u001b[92m ip\u001b[92m address\u001b[92m 127.0.0.1/8\n",
      "\u001b[92m ip\u001b[92m address\u001b[92m 10.2.2.100\u001b[92m secondary\n",
      "\u001b[92m ipv6\u001b[92m address\u001b[92m ::1/128\n",
      "\u001b[92m ip\u001b[92m ospf\u001b[92m cost\u001b[92m 1\n",
      "\u001b[92m !\n",
      "\u001b[92m interface\u001b[92m lo.management\n",
      "\u001b[92m ip\u001b[92m vrf\u001b[92m forwarding\u001b[92m management\n",
      "\u001b[92m ip\u001b[92m address\u001b[92m 127.0.0.1/8\n",
      "\u001b[92m ipv6\u001b[92m address\u001b[92m ::1/128\n",
      "\u001b[92m mtu\u001b[92m 1500\n",
      "\u001b[92m !\n",
      "\u001b[92m router\u001b[92m ospf\n",
      "\u001b[92m ospf\u001b[92m router-id\u001b[92m 10.2.2.100\n",
      "\u001b[92m bfd\u001b[92m all-interfaces\n",
      "\u001b[92m timers\u001b[92m spf\u001b[92m exp\u001b[92m 50\u001b[92m 50\n",
      "\u001b[92m timers\u001b[92m throttle\u001b[92m lsa\u001b[92m all\u001b[92m 0\u001b[92m 1\u001b[92m 1\n",
      "\u001b[92m timers\u001b[92m lsa\u001b[92m arrival\u001b[92m 1\n",
      "\u001b[92m passive-interface\u001b[92m lo\n",
      "\u001b[92m ospf\u001b[94m point-point\u001b[94m rfc-incompatible\n",
      "\u001b[94m network\u001b[94m 10.0.1.10/32\u001b[94m area\u001b[94m 0.0.0.0\n",
      "\u001b[94m network\u001b[94m 10.2.1.0/30\u001b[94m area\u001b[94m 0.0.0.0\n",
      "\u001b[94m network\u001b[94m 10.2.2.0/30\u001b[94m area\u001b[94m 0.0.0.0\n",
      "\u001b[94m network\u001b[94m 10.2.3.0/30\u001b[94m area\u001b[94m 0.0.0.0\n",
      "\u001b[94m network\u001b[94m 10.2.3.0/30\u001b[94m area\u001b[94m 0.0.0.0\n",
      "\u001b[94m network\u001b[94m 10.2.4.0/30\u001b[94m area\u001b[94m 0.0.0.0\n",
      "\u001b[94m !\n",
      "\u001b[94m ip\u001b[94m route\u001b[94m vrf\u001b[94m management\u001b[94m 0.0.0.0/0\u001b[94m 10.0.1.10\u001b[94m eth0\n",
      "\u001b[94m !\n",
      "\u001b[94m line\u001b[94m con\u001b[94m 0\n",
      "\u001b[94m exec-timeout\u001b[94m 240\u001b[94m 0\n",
      "\u001b[94m line\u001b[94m vty\u001b[94m 0\u001b[94m 39\n",
      "\u001b[94m exec-timeout\u001b[94m 240\u001b[94m 0\n",
      "\u001b[94m !\n",
      "\u001b[94m end\n",
      "\u001b[94m !\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score, acc = predict_config_accuracy(\"./config_PE-100.cfg\", mymodel, tokenizer)\n",
    "#y_probability,_ = compute_config_anomaly_vector(\"./config_PE-100.cfg\",mymodel,tokenizer)\n",
    "#y_words = display_config_anomalies(\"./config_PE-100.cfg\",mymodel,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7331326-200e-4131-b2b4-03020564932c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
