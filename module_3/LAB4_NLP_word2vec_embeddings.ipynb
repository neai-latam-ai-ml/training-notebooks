{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202b2c90",
   "metadata": {},
   "source": [
    "## **Install required libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b44d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch=2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "021efecd-68d3-48be-9b30-3a4626ea93cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-aws 0.2.15 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.3.0rc1 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.0rc1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /home/ubuntu/venv/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m167.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: smart-open, numpy, scipy, gensim\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 2.3.0rc1\n",
      "\u001b[2K    Uninstalling numpy-2.3.0rc1:\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.0rc1\n",
      "\u001b[2K  Attempting uninstall: scipy[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: scipy 1.15.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling scipy-1.15.3:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.15.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [scipy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [gensim]2m3/4\u001b[0m [gensim]\n",
      "\u001b[1A\u001b[2KSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy>=2.0.0 -U --pre\n",
    "!pip install scipy>=1.14.0 -U\n",
    "!pip install gensim -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ca344",
   "metadata": {},
   "source": [
    "## **Import required libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6df38e-7665-4e19-b8c0-e75531738e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eaa895",
   "metadata": {},
   "source": [
    "## **Download and load word2vec-google-news-300 model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a804ce-fb7d-4221-950e-ef2562180141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load word2vec-google-news-300 model...\n",
      "[--------------------------------------------------] 1.4% 23.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==------------------------------------------------] 4.0% 66.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===-----------------------------------------------] 6.5% 108.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "Model loaded successfully using gensim.downloader!\n",
      "Finding most similar words to 'woman':\n",
      "[('man', 0.7664012908935547), ('girl', 0.7494640946388245), ('teenage_girl', 0.7336829304695129), ('teenager', 0.6317085027694702), ('lady', 0.6288785934448242), ('teenaged_girl', 0.6141784191131592), ('mother', 0.6076306104660034), ('policewoman', 0.6069462299346924), ('boy', 0.5975907444953918), ('Woman', 0.5770983099937439)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    # Download and load the Google News Word2Vec model\n",
    "    # This will download the compressed file and extract it for you\n",
    "    print(\"Attempting to load word2vec-google-news-300 model...\")\n",
    "    model_path = api.load(\"word2vec-google-news-300\", return_path=True)\n",
    "    model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "    print(\"Model loaded successfully using gensim.downloader!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure your NumPy and Gensim libraries are up to date.\")\n",
    "    print(\"Try running: pip install --upgrade numpy gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f97c59",
   "metadata": {},
   "source": [
    "## \\*\\*Test example - Find the most similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finding most similar words to 'woman':\")\n",
    "print(model.most_similar('woman'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a7c5dd",
   "metadata": {},
   "source": [
    "## **Get the array for man**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fafa8ecc-7a81-4d31-8bda-9fa3cfd3e692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32617188,  0.13085938,  0.03466797, -0.08300781,  0.08984375,\n",
       "       -0.04125977, -0.19824219,  0.00689697,  0.14355469,  0.0019455 ,\n",
       "        0.02880859, -0.25      , -0.08398438, -0.15136719, -0.10205078,\n",
       "        0.04077148, -0.09765625,  0.05932617,  0.02978516, -0.10058594,\n",
       "       -0.13085938,  0.001297  ,  0.02612305, -0.27148438,  0.06396484,\n",
       "       -0.19140625, -0.078125  ,  0.25976562,  0.375     , -0.04541016,\n",
       "        0.16210938,  0.13671875, -0.06396484, -0.02062988, -0.09667969,\n",
       "        0.25390625,  0.24804688, -0.12695312,  0.07177734,  0.3203125 ,\n",
       "        0.03149414, -0.03857422,  0.21191406, -0.00811768,  0.22265625,\n",
       "       -0.13476562, -0.07617188,  0.01049805, -0.05175781,  0.03808594,\n",
       "       -0.13378906,  0.125     ,  0.0559082 , -0.18261719,  0.08154297,\n",
       "       -0.08447266, -0.07763672, -0.04345703,  0.08105469, -0.01092529,\n",
       "        0.17480469,  0.30664062, -0.04321289, -0.01416016,  0.09082031,\n",
       "       -0.00927734, -0.03442383, -0.11523438,  0.12451172, -0.0246582 ,\n",
       "        0.08544922,  0.14355469, -0.27734375,  0.03662109, -0.11035156,\n",
       "        0.13085938, -0.01721191, -0.08056641, -0.00708008, -0.02954102,\n",
       "        0.30078125, -0.09033203,  0.03149414, -0.18652344, -0.11181641,\n",
       "        0.10253906, -0.25976562, -0.02209473,  0.16796875, -0.05322266,\n",
       "       -0.14550781, -0.01049805, -0.03039551, -0.03857422,  0.11523438,\n",
       "       -0.0062561 , -0.13964844,  0.08007812,  0.06103516, -0.15332031,\n",
       "       -0.11132812, -0.14160156,  0.19824219, -0.06933594,  0.29296875,\n",
       "       -0.16015625,  0.20898438,  0.00041771,  0.01831055, -0.20214844,\n",
       "        0.04760742,  0.05810547, -0.0123291 , -0.01989746, -0.00364685,\n",
       "       -0.0135498 , -0.08251953, -0.03149414,  0.00717163,  0.20117188,\n",
       "        0.08300781, -0.0480957 , -0.26367188, -0.09667969, -0.22558594,\n",
       "       -0.09667969,  0.06494141, -0.02502441,  0.08496094,  0.03198242,\n",
       "       -0.07568359, -0.25390625, -0.11669922, -0.01446533, -0.16015625,\n",
       "       -0.00701904, -0.05712891,  0.02807617, -0.09179688,  0.25195312,\n",
       "        0.24121094,  0.06640625,  0.12988281,  0.17089844, -0.13671875,\n",
       "        0.1875    , -0.10009766, -0.04199219, -0.12011719,  0.00524902,\n",
       "        0.15625   , -0.203125  , -0.07128906, -0.06103516,  0.01635742,\n",
       "        0.18261719,  0.03588867, -0.04248047,  0.16796875, -0.15039062,\n",
       "       -0.16992188,  0.01831055,  0.27734375, -0.01269531, -0.0390625 ,\n",
       "       -0.15429688,  0.18457031, -0.07910156,  0.09033203, -0.02709961,\n",
       "        0.08251953,  0.06738281, -0.16113281, -0.19628906, -0.15234375,\n",
       "       -0.04711914,  0.04760742,  0.05908203, -0.16894531, -0.14941406,\n",
       "        0.12988281,  0.04321289,  0.02624512, -0.1796875 , -0.19628906,\n",
       "        0.06445312,  0.08935547,  0.1640625 , -0.03808594, -0.09814453,\n",
       "       -0.01483154,  0.1875    ,  0.12792969,  0.22753906,  0.01818848,\n",
       "       -0.07958984, -0.11376953, -0.06933594, -0.15527344, -0.08105469,\n",
       "       -0.09277344, -0.11328125, -0.15136719, -0.08007812, -0.05126953,\n",
       "       -0.15332031,  0.11669922,  0.06835938,  0.0324707 , -0.33984375,\n",
       "       -0.08154297, -0.08349609,  0.04003906,  0.04907227, -0.24121094,\n",
       "       -0.13476562, -0.05932617,  0.12158203, -0.34179688,  0.16503906,\n",
       "        0.06176758, -0.18164062,  0.20117188, -0.07714844,  0.1640625 ,\n",
       "        0.00402832,  0.30273438, -0.10009766, -0.13671875, -0.05957031,\n",
       "        0.0625    , -0.21289062, -0.06542969,  0.1796875 , -0.07763672,\n",
       "       -0.01928711, -0.15039062, -0.00106049,  0.03417969,  0.03344727,\n",
       "        0.19335938,  0.01965332, -0.19921875, -0.10644531,  0.01525879,\n",
       "        0.00927734,  0.01416016, -0.02392578,  0.05883789,  0.02368164,\n",
       "        0.125     ,  0.04760742, -0.05566406,  0.11572266,  0.14746094,\n",
       "        0.1015625 , -0.07128906, -0.07714844, -0.12597656,  0.0291748 ,\n",
       "        0.09521484, -0.12402344, -0.109375  , -0.12890625,  0.16308594,\n",
       "        0.28320312, -0.03149414,  0.12304688, -0.23242188, -0.09375   ,\n",
       "       -0.12988281,  0.0135498 , -0.03881836, -0.08251953,  0.00897217,\n",
       "        0.16308594,  0.10546875, -0.13867188, -0.16503906, -0.03857422,\n",
       "        0.10839844, -0.10498047,  0.06396484,  0.38867188, -0.05981445,\n",
       "       -0.0612793 , -0.10449219, -0.16796875,  0.07177734,  0.13964844,\n",
       "        0.15527344, -0.03125   , -0.20214844, -0.12988281, -0.10058594,\n",
       "       -0.06396484, -0.08349609, -0.30273438, -0.08007812,  0.02099609],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['man']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc72031",
   "metadata": {},
   "source": [
    "## **Print how many features (based on the model)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d24c5-5cf2-45b3-a726-82409f4b6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model['man'].shape #300 features (300 dimentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543d30c",
   "metadata": {},
   "source": [
    "## **Examples**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada5bae-8e2a-4103-8120-290fafd3d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c6be1-0e3e-4211-abb9-ec2aba80586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('BGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c5d92-6b86-40e6-88d1-7829a7e63c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.similarity('man', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec86f1-3279-4790-b92c-f99a3b735919",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.doesnt_match(['BGP', 'OSPF', 'ISIS', 'apple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a617759-d7e8-48e9-9b5c-987f20f184d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = model['king'] - model['man'] + model['woman']\n",
    "model.most_similar([vec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3277ff29",
   "metadata": {},
   "source": [
    "## **Get embeddings (the first 10 features) for a set of words**\n",
    "\n",
    "Get embeddings limited to the first 10 features.\n",
    "Create an array with them.\n",
    "Create a pandas data frame using the features and the words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a34499f-2875-4379-9d04-3743301da325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# king, queen, woman, girl, man, water\n",
    "words = ['king', 'queen', 'woman', 'girl', 'man', 'water']\n",
    "embeddings = np.array([\n",
    "    model['king'][0:10],\n",
    "    model['queen'][0:10],\n",
    "    model['woman'][0:10],\n",
    "    model['girl'][0:10],\n",
    "    model['man'][0:10],\n",
    "    model['water'][0:10]\n",
    "])\n",
    "\n",
    "df = pd.DataFrame(embeddings, index=words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c68e0",
   "metadata": {},
   "source": [
    "## **Generate the plot based on the dataframe generated**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237cc880-f78a-43a6-96bd-fc04c24c0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a hashmap\n",
    "plt.figure(figsize=(18,16))\n",
    "heatmap = sns.heatmap(df, cmap='crest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
