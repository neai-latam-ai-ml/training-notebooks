{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importing relevant libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziOcLB5XkvLh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load and preprocess data\n",
    "df = pd.read_csv(\"./spam/SMSSpamCollection\", sep=\"\\t\", names=[\"type\", \"message\"])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"spam\"] = df[\"type\"] == \"spam\"\n",
    "df.drop(\"type\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71kogpMhlJtd"
   },
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.8, random_state=0)\n",
    "df_val = df.drop(index=df_train.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Vectorize text data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Vectorize text data\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "messages_train_sparse = vectorizer.fit_transform(df_train['message'])\n",
    "messages_val_sparse = vectorizer.transform(df_val[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Convert Data to TensorFlow tensors**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r4hu4P2tlXNk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748391077.744668   41759 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 711 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# 3. Convert data to TensorFlow tensors\n",
    "X_train = tf.convert_to_tensor(messages_train_sparse.todense(), dtype=tf.float32)\n",
    "y_train_numpy = df_train[\"spam\"].values.astype(np.float32)\n",
    "y_train = tf.reshape(tf.convert_to_tensor(y_train_numpy), (-1, 1))\n",
    "\n",
    "X_val = tf.convert_to_tensor(messages_val_sparse.todense(), dtype=tf.float32)\n",
    "y_val_numpy = df_val[\"spam\"].values.astype(np.float32)\n",
    "y_val = tf.reshape(tf.convert_to_tensor(y_val_numpy), (-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciGPMBFBlbR6",
    "outputId": "047b1869-ca9f-4f69-a30f-399d25cfd354"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6988893151283264\n",
      "Epoch 1000, Loss: 0.297661691904068\n",
      "Epoch 2000, Loss: 0.22215718030929565\n",
      "Epoch 3000, Loss: 0.184007927775383\n",
      "Epoch 4000, Loss: 0.16059818863868713\n",
      "Epoch 5000, Loss: 0.14452345669269562\n",
      "Epoch 6000, Loss: 0.13266555964946747\n",
      "Epoch 7000, Loss: 0.12347403913736343\n",
      "Epoch 8000, Loss: 0.11608579754829407\n",
      "Epoch 9000, Loss: 0.10997981578111649\n",
      "Epoch 10000, Loss: 0.10482170432806015\n",
      "Epoch 11000, Loss: 0.10038641840219498\n",
      "Epoch 12000, Loss: 0.09651653468608856\n",
      "Epoch 13000, Loss: 0.09309840947389603\n",
      "Epoch 14000, Loss: 0.09004782885313034\n",
      "\n",
      "Sigmoid outputs on training data:\n",
      "tf.Tensor(\n",
      "[[0.02522809]\n",
      " [0.5660913 ]\n",
      " [0.06705257]\n",
      " ...\n",
      " [0.03438564]\n",
      " [0.00144189]\n",
      " [0.04097299]], shape=(4458, 1), dtype=float32)\n",
      "Min sigmoid output: 2.673478771697546e-09\n",
      "Max sigmoid output: 0.9995961785316467\n"
     ]
    }
   ],
   "source": [
    "# 4. Define the model, loss function, and optimizer using TensorFlow Keras\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(5000,))\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training Loop**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Training loop\n",
    "epochs = 15000\n",
    "for i in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(X_train, training=True)\n",
    "        loss = loss_fn(y_train, outputs)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Epoch {i}, Loss: {loss.numpy()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluate the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Evaluate the model\n",
    "y_pred_sigmoid_train = tf.nn.sigmoid(model(X_train, training=False))\n",
    "print(\"\\nSigmoid outputs on training data:\")\n",
    "print(y_pred_sigmoid_train)\n",
    "print(f\"Min sigmoid output: {tf.reduce_min(y_pred_sigmoid_train).numpy()}\")\n",
    "print(f\"Max sigmoid output: {tf.reduce_max(y_pred_sigmoid_train).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define evaluation function**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmzwjkxTl-t9",
    "outputId": "d94025e4-71f5-413a-c2f9-6eefe38c9368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on the training data\n",
      "accuracy: 0.9789143204689026\n",
      "sensitivity: 0.9226973652839661\n",
      "specificity: 0.9877921938896179\n",
      "precision: 0.9226973652839661\n",
      "\n",
      "Evaluating on the validation data\n",
      "accuracy: 0.9757630228996277\n",
      "sensitivity: 0.9208633303642273\n",
      "specificity: 0.983589768409729\n",
      "precision: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "# 7. Define evaluation function\n",
    "def evaluate_model_tf(X, y, threshold=0.25):\n",
    "    y_logits = model(X, training=False)\n",
    "    y_prob = tf.nn.sigmoid(y_logits)\n",
    "    y_pred_bool = y_prob > threshold\n",
    "\n",
    "    y_true_bool = tf.cast(y, tf.bool)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_bool, y_true_bool), tf.float32))\n",
    "    print(f\"accuracy: {accuracy.numpy()}\")\n",
    "\n",
    "    actual_positives_mask = tf.equal(y_true_bool, True)\n",
    "    if tf.reduce_sum(tf.cast(actual_positives_mask, tf.float32)).numpy() == 0:\n",
    "        sensitivity = float('nan')\n",
    "    else:\n",
    "        predicted_for_actual_positives = tf.boolean_mask(y_pred_bool, actual_positives_mask)\n",
    "        sensitivity = tf.reduce_mean(tf.cast(predicted_for_actual_positives, tf.float32))\n",
    "    print(f\"sensitivity: {sensitivity.numpy() if isinstance(sensitivity, tf.Tensor) else sensitivity}\")\n",
    "\n",
    "    actual_negatives_mask = tf.equal(y_true_bool, False)\n",
    "    if tf.reduce_sum(tf.cast(actual_negatives_mask, tf.float32)).numpy() == 0:\n",
    "        specificity = float('nan')\n",
    "    else:\n",
    "        predicted_for_actual_negatives = tf.boolean_mask(y_pred_bool, actual_negatives_mask)\n",
    "        specificity = tf.reduce_mean(tf.cast(tf.logical_not(predicted_for_actual_negatives), tf.float32))\n",
    "    print(f\"specificity: {specificity.numpy() if isinstance(specificity, tf.Tensor) else specificity}\")\n",
    "\n",
    "    predicted_positives_mask = tf.equal(y_pred_bool, True)\n",
    "    if tf.reduce_sum(tf.cast(predicted_positives_mask, tf.float32)).numpy() == 0:\n",
    "        precision = float('nan')\n",
    "    else:\n",
    "        actuals_for_predicted_positives = tf.boolean_mask(y_true_bool, predicted_positives_mask)\n",
    "        precision = tf.reduce_mean(tf.cast(actuals_for_predicted_positives, tf.float32))\n",
    "    print(f\"precision: {precision.numpy() if isinstance(precision, tf.Tensor) else precision}\")\n",
    "\n",
    "print(\"\\nEvaluating on the training data\")\n",
    "evaluate_model_tf(X_train, y_train)\n",
    "\n",
    "print(\"\\nEvaluating on the validation data\")\n",
    "evaluate_model_tf(X_val, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prediction**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cn5pqbCMnrls",
    "outputId": "4aeb6250-db8f-485b-c16c-ea624341fd77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for custom messages:\n",
      "Message: \"Winner! Great deal, call us to get this product for free\"\n",
      "Spam probability (TensorFlow): 0.6066\n",
      "Predicted as Spam (threshold 0.25): True\n",
      "--------------------\n",
      "Message: \"Tomorrow is my birthday, do you come to the party?\"\n",
      "Spam probability (TensorFlow): 0.0175\n",
      "Predicted as Spam (threshold 0.25): False\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 8. Predict on custom messages\n",
    "custom_messages_text = [\n",
    "    \"Winner! Great deal, call us to get this product for free\",\n",
    "    \"Tomorrow is my birthday, do you come to the party?\"\n",
    "]\n",
    "custom_messages_sparse = vectorizer.transform(custom_messages_text)\n",
    "X_custom = tf.convert_to_tensor(custom_messages_sparse.todense(), dtype=tf.float32)\n",
    "\n",
    "custom_preds_logits = model(X_custom, training=False)\n",
    "custom_preds_sigmoid = tf.nn.sigmoid(custom_preds_logits)\n",
    "\n",
    "print(\"\\nPredictions for custom messages:\")\n",
    "for i, text in enumerate(custom_messages_text):\n",
    "    print(f\"Message: \\\"{text}\\\"\")\n",
    "    print(f\"Spam probability (TensorFlow): {custom_preds_sigmoid[i].numpy()[0]:.4f}\")\n",
    "    print(f\"Predicted as Spam (threshold 0.25): {custom_preds_sigmoid[i].numpy()[0] > 0.25}\")\n",
    "    print(\"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
