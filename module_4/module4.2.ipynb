{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Network Engineering in the AI Era\n",
    "\n",
    "## Module 4.2 - Introduction to Agentic AI\n",
    "\n",
    "Welcome to this module on Agentic AI using LangGraph!\n",
    "In this notebook, we'll explore what agents are, how they operate, and build a practical example of an AI agent that can help with network configuration tasks.\n",
    "\n",
    "### What are AI Agents?\n",
    "\n",
    "AI agents are autonomous or semi-autonomous systems that can:\n",
    "\n",
    "- Perceive their environment through inputs and context\n",
    "- Process and reason about information\n",
    "- Make decisions and plan multi-step actions\n",
    "- Execute tasks by using tools and APIs\n",
    "- Learn from feedback and improve over time\n",
    "\n",
    "Unlike simple LLM applications that respond to single prompts, agents maintain state, make sequential decisions, and take actions to accomplish complex tasks.\n",
    "\n",
    "### Key Components of AI Agents\n",
    "\n",
    "- **Memory**: Ability to store and recall information from previous interactions\n",
    "- **Tools**: Functions or APIs that the agent can use to interact with external systems\n",
    "- **Planning**: Ability to break down complex tasks into manageable steps\n",
    "- **Reasoning**: Capability to make decisions based on available information\n",
    "- **Reflection**: Ability to evaluate performance and adjust strategies\n",
    "\n",
    "### LangGraph: Building Stateful Multi-Agent Systems\n",
    "\n",
    "LangGraph extends LangChain by providing a framework for creating stateful agents with:\n",
    "\n",
    "- A graph structure where nodes represent different agent states\n",
    "- Tools for managing transitions between states\n",
    "- Methods for orchestrating complex workflows with multiple agents\n",
    "\n",
    "Let's start by installing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-anthropic langchain-aws langchain-community langgraph langsmith boto3 rich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Our Environment\n",
    "\n",
    "In order to use LangGraph, we need to setup an LLM chain. We will use ChatBedrock since our inference endpoints are hosted on Bedrock.\n",
    "We will be use the Claude 3.7 model from Anthropic. This is one of the most advanced models available today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Use this if running from Google Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=\"your-key-id\",\n",
    "    aws_secret_access_key=\"your-key\",\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    model_kwargs=dict(temperature=0),\n",
    "    client=session.client(\"bedrock-runtime\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Use this if running from AWS directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    temperature=0,\n",
    "    region=\"us-east-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Our Agent's Components\n",
    "\n",
    "Our graph will have a single agent (the assistant) and some available tools.\n",
    "\n",
    "Let's start by defining the tools, and begin with our **Policy Lookup Tool**.\n",
    "\n",
    "This tool will take the markdown document `acme_guidelines.md` and will split it using the MarkdownHeaderTextSplitter (the same one we learned about on our previous module) and will store the resulting documents in a `InMemoryVectorStore`.\n",
    "This `InMemoryVectorStore` is no different than any other vector storage databases, it won't be used in a production environment but it is useful for training purposes.\n",
    "\n",
    "The lookup_policy tool once called, will do a similarity search on the documents stored in the `InMemoryVectorStore` and will return the most similar document to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Use this if running from Google Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "embeddings = BedrockEmbeddings(\n",
    "    model_id=\"amazon.titan-embed-text-v2:0\", \n",
    "    client=session.client(\"bedrock-runtime\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Use this if running from AWS directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "embeddings = BedrockEmbeddings(\n",
    "    model_id=\"amazon.titan-embed-text-v2:0\", \n",
    "    region_name='us-east-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "loader = TextLoader(\"acme_guidelines.md\")\n",
    "documents = loader.load()\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_splits = []\n",
    "for document in documents:\n",
    "    md_splits.extend(md_splitter.split_text(document.page_content))\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store.add_documents(md_splits)\n",
    "\n",
    "\n",
    "@tool\n",
    "def lookup_policy(\n",
    "    query: Annotated[str, \"The query to look for in the company policies.\"],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Consult the configuration guidelines.\n",
    "    Use this before making any network changes performing other 'write' events.\n",
    "    \"\"\"\n",
    "    docs = vector_store.similarity_search(query, k=2)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have done that, let's proceed with creating a tool that will allow the agent to configure devices. In this example, our tool will simulate sending the configuration to a device, and will instead print the configuration to the console. In a real-world scenario, you would replace this with actual code that sends the configuration to a device for example via RESTCONF or NETCONF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Please select the port number assigned to you. Update the `hostname` as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from netmiko import ConnectHandler\n",
    "\n",
    "devices = {\n",
    "    \"CTG-EDGE-001\": {\n",
    "        \"hostname\": \"54.81.253.219\", # Update IP based on lab details\n",
    "        \"username\": \"admin\",\n",
    "        \"password\": \"cisco123\",\n",
    "        \"port\": 8022, # Update the port accordingly\n",
    "    }\n",
    "}\n",
    "\n",
    "@tool\n",
    "def add_device_interface(\n",
    "    device_name: Annotated[str, \"The name of the device to configure.\"],\n",
    "    interface_name: Annotated[\n",
    "        str,\n",
    "        \"The interface name to apply the configuration to. E.g., 'Loopback100'\",\n",
    "    ],\n",
    "    interface_description: Annotated[str, \"The description to set for the interface.\"],\n",
    "    interface_ipv4_address: Annotated[\n",
    "        str, \"The IPv4 address to assign to the interface. E.g., 192.168.1.1\"\n",
    "    ],\n",
    "    interface_ipv4_subnet_mask: Annotated[\n",
    "        str, \"The IPv4 subnet mask to assign to the interface. E.g., 255.255.255.0\"\n",
    "    ],\n",
    ") -> str:\n",
    "    \"\"\"Use this tool to add an interface to a device.\"\"\"\n",
    "\n",
    "    connection = {\n",
    "        'device_type': 'cisco_xr',\n",
    "        'ip': devices[device_name][\"hostname\"],\n",
    "        'username': devices[device_name][\"username\"],\n",
    "        'password': devices[device_name][\"password\"],\n",
    "        'port': devices[device_name][\"port\"],\n",
    "        'secret': '',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    config_commands = [\n",
    "        f'interface {interface_name}',\n",
    "        f'description {interface_description}',\n",
    "        f'ipv4 address {interface_ipv4_address} {interface_ipv4_subnet_mask}',\n",
    "        'no shutdown'\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        net_connect = ConnectHandler(**connection)\n",
    "        net_connect.send_config_set(config_commands)\n",
    "        net_connect.send_command('commit')\n",
    "    except Exception as e:\n",
    "        return f\"Exception {e}\"\n",
    "\n",
    "    net_connect.disconnect()\n",
    "\n",
    "    return f\"Interface {interface_name} successfully configured\"\n",
    "   \n",
    "\n",
    "\n",
    "@tool\n",
    "def get_device_interface(\n",
    "    device_name: Annotated[str, \"The name of the device to configure.\"],\n",
    "    interface_name: Annotated[\n",
    "        str,\n",
    "        \"The interface name to apply the configuration to. E.g., 'Loopback100'\",\n",
    "    ],\n",
    ") -> str:\n",
    "    \"\"\"Use this tool to get the configuration for an interface of a device.\"\"\"\n",
    "\n",
    "    connection = {\n",
    "        'device_type': 'cisco_xr',\n",
    "        'ip': devices[device_name][\"hostname\"],\n",
    "        'username': devices[device_name][\"username\"],\n",
    "        'password': devices[device_name][\"password\"],\n",
    "        'port': devices[device_name][\"port\"],\n",
    "        'secret': '',\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    net_connect = ConnectHandler(**connection)\n",
    "    output = net_connect.send_command(f\"show interface {interface_name}\")\n",
    "    net_connect.disconnect()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an array that will contain the list of tools that will be available to our agent. The first tool we'll define is the policy lookup tool. This tool will allow the agent to look up network policies in the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "available_tools = [\n",
    "    lookup_policy,\n",
    "    add_device_interface,\n",
    "    get_device_interface,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our assistant agent that will have access to all the available tools. We'll define the agent as a class. This will allow us to easily add more tools in the future if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a helpful customer support assistant for ACME Service Provider. \"\n",
    "            \"Use the provided tools to create resources or to search for procedures, company policies, and other information to assist the user's queries. \"\n",
    "            \"When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \"If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\nCurrent time: {time}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\"messages\"),\n",
    "    ]\n",
    ").partial(time=datetime.now)\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    \"\"\"Assistant node for the graph.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the assistant.\"\"\"\n",
    "        self.runnable: Runnable = primary_assistant_prompt | llm.bind_tools(\n",
    "            available_tools\n",
    "        )\n",
    "\n",
    "    def __call__(self, state: MessagesState, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If the LLM happens to return an empty response, we will re-prompt it\n",
    "            # for an actual response.\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [\n",
    "                    HumanMessage(content=\"Respond with a real output.\")\n",
    "                ]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Agent Graph\n",
    "Now, let's connect all these components into a graph using LangGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes: these do the work\n",
    "workflow.add_node(\"assistant\", Assistant())\n",
    "workflow.add_node(\n",
    "    \"tools\",\n",
    "    ToolNode(available_tools),\n",
    ")\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "workflow.add_edge(START, \"assistant\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our graph to see how the nodes are connected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Our Network Configuration Agent\n",
    "Let's create a function to interact with our agent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage\n",
    "Let's test our agent with a few examples. Let's begin with asking our agent the following: **I need to create a new VLAN for my database server.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "initial_message = HumanMessage(\n",
    "    content=\"Configure interface Loopback101 on device CTG-EDGE-001 with IPv4 address 10.1.2.2/30, this interface will connect to BOG-CORE-001.\"\n",
    ")\n",
    "rich.print(initial_message.pretty_repr())\n",
    "for event in graph.stream(\n",
    "    {\"messages\": [initial_message]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for _, message_or_messages in event.items():\n",
    "        if isinstance(message_or_messages[\"messages\"], list):\n",
    "            for message in message_or_messages[\"messages\"]:\n",
    "                rich.print(message.pretty_repr())\n",
    "        else:\n",
    "            rich.print(message_or_messages[\"messages\"].pretty_repr())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now verify that the requested interface has been configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_message = HumanMessage(\n",
    "    content=\"In device CTG-EDGE-001, which IP is configured on interface Loopback101?\"\n",
    ")\n",
    "rich.print(initial_message.pretty_repr())\n",
    "for event in graph.stream(\n",
    "    {\"messages\": [initial_message]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for _, message_or_messages in event.items():\n",
    "        if isinstance(message_or_messages[\"messages\"], list):\n",
    "            for message in message_or_messages[\"messages\"]:\n",
    "                rich.print(message.pretty_repr())\n",
    "        else:\n",
    "            rich.print(message_or_messages[\"messages\"].pretty_repr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
