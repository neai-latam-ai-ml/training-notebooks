{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Network Engineering in the AI Era\n",
    "\n",
    "## Module 4.2 - Introduction to Agentic AI\n",
    "\n",
    "Welcome to this module on Agentic AI using LangGraph!\n",
    "In this notebook, we'll explore what agents are, how they operate, and build a practical example of an AI agent that can help with network configuration tasks.\n",
    "\n",
    "### What are AI Agents?\n",
    "\n",
    "AI agents are autonomous or semi-autonomous systems that can:\n",
    "\n",
    "- Perceive their environment through inputs and context\n",
    "- Process and reason about information\n",
    "- Make decisions and plan multi-step actions\n",
    "- Execute tasks by using tools and APIs\n",
    "- Learn from feedback and improve over time\n",
    "\n",
    "Unlike simple LLM applications that respond to single prompts, agents maintain state, make sequential decisions, and take actions to accomplish complex tasks.\n",
    "\n",
    "### Key Components of AI Agents\n",
    "\n",
    "- **Memory**: Ability to store and recall information from previous interactions\n",
    "- **Tools**: Functions or APIs that the agent can use to interact with external systems\n",
    "- **Planning**: Ability to break down complex tasks into manageable steps\n",
    "- **Reasoning**: Capability to make decisions based on available information\n",
    "- **Reflection**: Ability to evaluate performance and adjust strategies\n",
    "\n",
    "### LangGraph: Building Stateful Multi-Agent Systems\n",
    "\n",
    "LangGraph extends LangChain by providing a framework for creating stateful agents with:\n",
    "\n",
    "- A graph structure where nodes represent different agent states\n",
    "- Tools for managing transitions between states\n",
    "- Methods for orchestrating complex workflows with multiple agents\n",
    "\n",
    "Let's start by installing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain-anthropic langchain-aws langchain-community langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Our Environment\n",
    "\n",
    "In order to use LangGraph, we need to setup an llm chain. We will use ChatBedrock since our inference endpoints are hosted on Bedrock.\n",
    "We will be use the Claude 3.7 model from Anthropic. This is one of the most advanced models available today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    temperature=0,\n",
    "    region=\"us-east-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Our Agent's Components\n",
    "\n",
    "Our graph will have a single agent (the assistant) and some available tools.\n",
    "\n",
    "Let's start by defining the tools, and begin with our **Policy Lookup Tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "embeddings = BedrockEmbeddings(\n",
    "    model_id=\"amazon.titan-embed-text-v2:0\", region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "loader = TextLoader(\"acme_guidelines.md\")\n",
    "documents = loader.load()\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "md_splits = []\n",
    "for document in documents:\n",
    "    md_splits.extend(md_splitter.split_text(document.page_content))\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store.add_documents(md_splits)\n",
    "\n",
    "\n",
    "@tool\n",
    "def lookup_policy(\n",
    "    query: Annotated[str, \"The query to look for in the company policies.\"],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Consult the configuration guidelines.\n",
    "    Use this before making any network changes performing other 'write' events.\n",
    "    \"\"\"\n",
    "    docs = vector_store.similarity_search(query, k=2)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have done that, let's proceed with creating a tool that will allow the agent to configure devices. In this example, our tool will simulate sending the configuration to a device, and will instead print the configuration to the console. In a real-world scenario, you would replace this with actual code that sends the configuration to a device for example via RESTCONF or NETCONF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "import httpx\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "configuration_template = \"\"\"\n",
    "interface {interface_name}\n",
    "    description {interface_description}\n",
    "    ip address {interface_ipv4_address} {interface_ipv4_subnet_mask}\n",
    "    no shutdown\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def configure_device(\n",
    "    device_name: Annotated[str, \"The name of the device to configure.\"],\n",
    "    interface_name: Annotated[\n",
    "        str,\n",
    "        \"The interface name to apply the configuration to. E.g., 'GigabitEthernet0/1'\",\n",
    "    ],\n",
    "    interface_description: Annotated[str, \"The description to set for the interface.\"],\n",
    "    interface_ipv4_address: Annotated[\n",
    "        str, \"The IPv4 address to assign to the interface. E.g., 192.168.1.1\"\n",
    "    ],\n",
    "    interface_ipv4_subnet_mask: Annotated[\n",
    "        str, \"The IPv4 subnet mask to assign to the interface. E.g., 255.255.255.0\"\n",
    "    ],\n",
    ") -> bool:\n",
    "    \"\"\"Use this tool to configure the interface of a device.\"\"\"\n",
    "    configuration = configuration_template.format(\n",
    "        interface_name=interface_name,\n",
    "        interface_description=interface_description,\n",
    "        interface_ipv4_address=interface_ipv4_address,\n",
    "        interface_ipv4_subnet_mask=interface_ipv4_subnet_mask,\n",
    "    )\n",
    "    print(f\"{'=' * 10}\\n{configuration}\\n{'=' * 10}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "hostname = \"devnetsandboxiosxe.cisco.com\"\n",
    "uri = \"/restconf/data/ietf-interfaces:interfaces/interface=GigabitEthernet2\"\n",
    "username = \"admin\"\n",
    "password = \"C1sco12345\"\n",
    "\n",
    "payload = {\"primary\": {\"address\": \"100.100.100.1\", \"mask\": \"255.255.255.0\"}}\n",
    "\n",
    "# RESTCONF media types for REST API headers\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/yang-data+json\",\n",
    "    \"Accept\": \"application/yang-data+json\",\n",
    "}\n",
    "\n",
    "response = httpx.get(\n",
    "    f\"https://{hostname}/{uri}\",\n",
    "    auth=(username, password),\n",
    "    headers=headers,\n",
    "    verify=False,\n",
    ")\n",
    "print(response.text)\n",
    "uri = \"/restconf/data/Cisco-IOS-XE-native:native/interface/GigabitEthernet=2.100/ip/address/primary\"\n",
    "response = httpx.post(\n",
    "    f\"https://{hostname}/{uri}\",\n",
    "    auth=(username, password),\n",
    "    headers=headers,\n",
    "    json=payload,\n",
    "    verify=False,\n",
    ")\n",
    "\n",
    "# print the json that is returned\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an array that will contain the list of tools that will be available to our agent. The first tool we'll define is the policy lookup tool. This tool will allow the agent to look up network policies in the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    \"\"\"Handle the error from the tool.\"\"\"\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "available_tools = [\n",
    "    lookup_policy,\n",
    "    configure_device,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our assistant agent that will have access to all the available tools. We'll define the agent as a class. This will allow us to easily add more tools in the future if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful customer support assistant for ACME Service Provider. \"\n",
    "            \"Use the provided tools to create resources or to search for procedures, company policies, and other information to assist the user's queries. \"\n",
    "            \"When searching, be persistent. Expand your query bounds if the first search returns no results. \"\n",
    "            \"If a search comes up empty, expand your search before giving up.\"\n",
    "            \"\\nCurrent time: {time}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\"messages\"),\n",
    "    ]\n",
    ").partial(time=datetime.now)\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    \"\"\"Assistant node for the graph.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the assistant.\"\"\"\n",
    "        self.runnable: Runnable = primary_assistant_prompt | llm.bind_tools(\n",
    "            available_tools\n",
    "        )\n",
    "\n",
    "    def __call__(self, state: MessagesState, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If the LLM happens to return an empty response, we will re-prompt it\n",
    "            # for an actual response.\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [\n",
    "                    HumanMessage(content=\"Respond with a real output.\")\n",
    "                ]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Agent Graph\n",
    "Now, let's connect all these components into a graph using LangGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes: these do the work\n",
    "workflow.add_node(\"assistant\", Assistant())\n",
    "workflow.add_node(\n",
    "    \"tools\",\n",
    "    ToolNode(available_tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)],\n",
    "        exceptions_to_handle=(httpx.RequestError,),\n",
    "        exception_key=\"error\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "workflow.add_edge(START, \"assistant\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition,\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our graph to see how the nodes are connected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Our Network Configuration Agent\n",
    "Let's create a function to interact with our agent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage\n",
    "Let's test our agent with a few examples. Let's begin with asking our agent the following: **I need to create a new VLAN for my database server.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for event in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Configure interface GigabitEthernet1/0/0 on device CTG-EDGE-001 with IPv4 address 10.1.2.1/30, this interface will connect to BOG-CORE-001.\"\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    rich.print(event)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
